{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9026b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abb37cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIFt(object):\n",
    "    def __init__(self, pickled_sift):\n",
    "        \n",
    "        if pickled_sift is None:\n",
    "            print(\"ohno\")\n",
    "            return None\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize an SIFt class.\n",
    "        Parameters:\n",
    "            fn_pro_PDB - PDB file name of the protein\n",
    "            fn_lig_PDB - PDB file name of the ligand\n",
    "            fn_pro_MOL2 - MOL2 file name of the protein\n",
    "            fn_lig_MOL2 - MOL2 file name of the ligand\n",
    "            ID - ID of the complex\n",
    "            addH - whether to add hydrogen atoms when reading in the structure file\n",
    "            sant - whether to sanitize the molecule when reading in the structure file\n",
    "            int_cutoff - distance threshold for identifying protein-ligand interacting atoms \n",
    "        \"\"\"\n",
    "        self.ID = pickled_sift.ID \n",
    "       # print('Constructing an SIFt object for %s.........\\n' % self.ID)\n",
    "        # read in pdb coordinates and topology\n",
    "        self.lig = pickled_sift.lig\n",
    "        self.pro = pickled_sift.pro\n",
    "\n",
    " \n",
    "       \n",
    "        # parse protein pdb file for identifying sidechain/mainchain atoms\n",
    "#        parser = PDBParser()\n",
    "#        self.structure = parser.get_structure(self.ID, fn_pro_PDB)\n",
    "#        self.chid = self.pro[1].GetAtomWithIdx(0).GetPDBResidueInfo().GetChainId()\n",
    "        # identify interacting area\n",
    "        self.contact_bins = pickled_sift.contact_bins\n",
    "        self.pd = pickled_sift.pd\n",
    "        self.cont = pickled_sift.cont\n",
    "        self.contacts = pickled_sift.contacts\n",
    "\n",
    "        self.protein_env = pickled_sift.protein_env\n",
    "        self.ligand_env = pickled_sift.ligand_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee2e99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_descriptors(csv_path, embeddings_root):\n",
    "    \"\"\"\n",
    "    Load descriptors and labels from a CSV file and embeddings folder structure.\n",
    "\n",
    "    CSV must have columns: 'protein_name', 'binding_affinity'.\n",
    "    For each protein_name, expects files:\n",
    "        embeddings_root/protein_name/protein_esm.pkl\n",
    "        embeddings_root/protein_name/ligand_embedding.pkl\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        pname = row['id']\n",
    "        affinity = row['affinity']\n",
    "        subfolder = os.path.join(embeddings_root, pname)\n",
    "        \n",
    "\n",
    "        esm_file = os.path.join(subfolder, 'protein_esm.pkl')\n",
    "        lig_file = os.path.join(subfolder, 'ligand_embedding.pkl')\n",
    "\n",
    "        # Load embeddings\n",
    "        try:\n",
    "            with open(esm_file, 'rb') as f:\n",
    "                prot_vec = pickle.load(f)\n",
    "            with open(lig_file, 'rb') as f:\n",
    "                lig_vec = pickle.load(f)\n",
    "        except:\n",
    "            continue\n",
    "        # Concatenate descriptors\n",
    "        descriptor = np.concatenate([prot_vec, lig_vec])\n",
    "\n",
    "        X_list.append(descriptor)\n",
    "        y_list.append(affinity)\n",
    "\n",
    "    X = np.vstack(X_list)\n",
    "    y = np.array(y_list, dtype=float)\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65e8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_validate_models(X, y, n_splits=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform K-Fold CV for three regression models and return CV metrics.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        # 'RandomForest1': RandomForestRegressor(random_state=random_state,n_estimators = 100),\n",
    "        # 'RandomForest2': RandomForestRegressor(random_state=random_state,n_estimators = 200),\n",
    "        # 'RandomForest3': RandomForestRegressor(random_state=random_state,n_estimators = 300),\n",
    "        # 'RandomForest4': RandomForestRegressor(random_state=random_state,n_estimators = 400),\n",
    "        # 'RandomForest5': RandomForestRegressor(random_state=random_state,n_estimators = 450),\n",
    "        # 'RandomForest6': RandomForestRegressor(random_state=random_state,n_estimators = 500),\n",
    "        # 'RandomForest7': RandomForestRegressor(random_state=random_state,n_estimators = 550),\n",
    "        'RandomForest8': RandomForestRegressor(random_state=random_state,n_estimators = 600),\n",
    "        # 'RandomForest9': RandomForestRegressor(random_state=random_state,n_estimators = 650),\n",
    "        # 'RandomForest10': RandomForestRegressor(random_state=random_state,n_estimators = 700),   \n",
    "        # 'GradientBoosting1': GradientBoostingRegressor(random_state=random_state,n_estimators=100),\n",
    "        # 'GradientBoosting2': GradientBoostingRegressor(random_state=random_state,n_estimators=200),\n",
    "        # 'GradientBoosting3': GradientBoostingRegressor(random_state=random_state,n_estimators=300),\n",
    "        # 'GradientBoosting4': GradientBoostingRegressor(random_state=random_state,n_estimators=400),\n",
    "        # 'GradientBoosting5': GradientBoostingRegressor(random_state=random_state,n_estimators=450),\n",
    "        # 'GradientBoosting6': GradientBoostingRegressor(random_state=random_state,n_estimators=500),\n",
    "        # 'GradientBoosting7': GradientBoostingRegressor(random_state=random_state,n_estimators=550),\n",
    "        # 'GradientBoosting8': GradientBoostingRegressor(random_state=random_state,n_estimators=600),\n",
    "        # 'GradientBoosting9': GradientBoostingRegressor(random_state=random_state,n_estimators=700),\n",
    "        # \"svr_poly1\" : SVR(kernel='poly', degree=4, C=1.0, epsilon=0.1, coef0=1),\n",
    "        # \"svr_poly2\" : SVR(kernel='poly', degree=4, C=1.0, epsilon=0.1, coef0=2),\n",
    "        # \"svr_poly3\" : SVR(kernel='poly', degree=4, C=1.0, epsilon=0.1, coef0=3),\n",
    "    }\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    cv_results = {name: {'pearson': [], 'rmse': []} for name in models}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(\"doing\",name)\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            print(len(val_idx))\n",
    "            X_tr, X_val = X[train_idx], X[val_idx]\n",
    "            y_tr, y_val = y[train_idx], y[val_idx]\n",
    "            model.fit(X_tr, y_tr)\n",
    "            y_pred = model.predict(X_val)\n",
    "            # Metrics\n",
    "            r, _ = pearsonr(y_val, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "            cv_results[name]['pearson'].append(r)\n",
    "            cv_results[name]['rmse'].append(rmse)\n",
    "\n",
    "        # Aggregate\n",
    "        pearson_vals = cv_results[name]['pearson']\n",
    "        rmse_vals    = cv_results[name]['rmse']\n",
    "\n",
    "        pearson_mean = np.mean(pearson_vals)\n",
    "        pearson_std  = np.std(pearson_vals, ddof=1)   # sample std\n",
    "        rmse_mean    = np.mean(rmse_vals)\n",
    "        rmse_std     = np.std(rmse_vals, ddof=1)      # sample std\n",
    "\n",
    "        print(\n",
    "            f\"{name} CV -> \"\n",
    "            f\"Pearson: {pearson_mean:.3f} ± {pearson_std:.3f}, \"\n",
    "            f\"RMSE: {rmse_mean:.3f} ± {rmse_std:.3f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    return cv_results, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d07a7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_test(train_csv, train_root, test_csv, test_root):\n",
    "    # Load training data\n",
    "    X_train, y_train = load_descriptors(train_csv, train_root)\n",
    "    print(f\"Training samples: {X_train.shape[0]}, features: {X_train.shape[1]}\")\n",
    "\n",
    "    # Cross-validate\n",
    "    cv_results, models = cross_validate_models(X_train, y_train)\n",
    "\n",
    "    # Train final models on all training data and evaluate on test set\n",
    "    X_test, y_test = load_descriptors(test_csv, test_root)\n",
    "    print(f\"Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        r, _ = pearsonr(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        print(f\"{name} Test -> Pearson: {r:.3f}, RMSE: {rmse:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dbe966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 4826, features: 384\n",
      "doing RandomForest8\n",
      "483\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Paths to CSVs and embedding folders\n",
    "    train_csv_path = '/home/ansh-meshram/Desktop/work/bio_project/PDBbind/indexes/rs_index.csv'       # CSV with 'protein_name' and 'binding_affinity'\n",
    "    train_emb_folder = '/home/ansh-meshram/Desktop/work/bio_project/PDBbind/data'   # Folder containing subfolders per protein\n",
    "    test_csv_path = '/home/ansh-meshram/Desktop/work/bio_project/PDBbind/indexes/casf2016_index.csv'\n",
    "    test_emb_folder = '/home/ansh-meshram/Desktop/work/bio_project/PDBbind/data'\n",
    "\n",
    "    train_and_test(train_csv_path, train_emb_folder, test_csv_path, test_emb_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571de71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d43644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
